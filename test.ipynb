{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda create -n matcha_gnn python=3.10\n",
    "#!conda activate matcha_gnn\n",
    "#!pip install datasets\n",
    "#!pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "#!pip install sentencepiece\n",
    "#!pip install transformers\n",
    "#!pip install pip install  dgl -f https://data.dgl.ai/wheels/torch-2.3/cu118/repo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matcha_dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the testing dataset\n",
    "dataset = load_dataset(\"krr-oxford/OntoLAMA\", \"doid-atomic-SI\")\n",
    "for partition in dataset:\n",
    "    print(partition, dataset[partition])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matcha_gnn import datasets\n",
    "\n",
    "## create dataset object for source and target ontologies\n",
    "g = datasets.DGLDataset(\n",
    "    source_ontology=\"ontologies/doid.owl\" ,\n",
    "    target_ontology=\"ontologies/go.owl\",\n",
    "    heterogeneous=True)\n",
    "\n",
    "# g.graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "import torch\n",
    "from matcha_gnn import gnns, GridSearchCV\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "## create model, optimizer, scheduler and loss function\n",
    "## and call the trainer\n",
    "\n",
    "# Sampler\n",
    "\n",
    "# Loader\n",
    "\n",
    "# define model and optimizer\n",
    "model = gnns.GCN\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=1)\n",
    "CrossEntropy = torch.nn.CrossEntropyLoss()\n",
    "gs = GridSearchCV(g, model, optimizer, scheduler, CrossEntropy, epochs=100)\n",
    "params = {\n",
    "    'lr': [0.1, 0.01, 0.001],\n",
    "    'hidden_dim': [64, 128],\n",
    "    'num_layers': [1, 2],\n",
    "    'dropout': [0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "for i in range(10):\n",
    "    # train and test the model\n",
    "    loss, results = gs.predict(i, g.graph, features, labels, params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
